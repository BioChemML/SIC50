{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "\n",
    "TRAINING_DIR = ('D:\\\\1_Projects_at_UC_Davis\\\\0_Research1_ML_Weidi\\\\c-1\\\\train')\n",
    "training_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "\t    rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "VALIDATION_DIR = ('D:\\\\1_Projects_at_UC_Davis\\\\0_Research1_ML_Weidi\\\\c-1\\\\test')\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = training_datagen.flow_from_directory(\n",
    "\tTRAINING_DIR,\n",
    "\ttarget_size=(198,198),\n",
    "\tclass_mode='categorical',\n",
    "  batch_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "\tVALIDATION_DIR,\n",
    "\ttarget_size=(198,198),\n",
    "\tclass_mode='categorical',\n",
    "  batch_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "class VGG16(object):\n",
    "\n",
    "\t\"\"\" Implementation of VGG16 network \"\"\"\n",
    "\n",
    "\tdef __init__(self, x, keep_prob, num_classes):\n",
    "\n",
    "\t\t\"\"\"Create the graph of the AlexNet model.\n",
    "        Args:\n",
    "            x: Placeholder for the input tensor.\n",
    "            keep_prob: Dropout probability.\n",
    "            num_classes: Number of classes in the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        # Parse input arguments into class variables\n",
    "\t\tself.X = x\n",
    "\t\tself.NUM_CLASSES = num_classes\n",
    "\t\tself.KEEP_PROB = keep_prob\n",
    "\n",
    "\t\t# Call the create function to build the computational graph of AlexNet\n",
    "\t\tself.create()\n",
    "\n",
    "\tdef create(self):\n",
    "\n",
    "\t\t\"\"\"Create the network graph.\"\"\"\n",
    "\n",
    "\t\tconv1_1 = conv_layer(self.X, 64, 'conv1_1')\n",
    "\t\tconv1_2 = conv_layer(conv1_1, 64, 'conv1_2')\n",
    "\t\tpool1 = max_pool(conv1_2, 'pool1')\n",
    "\n",
    "\t\tconv2_1 = conv_layer(pool1, 128, 'conv2_1')\n",
    "\t\tconv2_2 = conv_layer(conv2_1, 128, 'conv2_2')\n",
    "\t\tpool2 = max_pool(conv2_2, 'pool2')\n",
    "\n",
    "\t\tconv3_1 = conv_layer(pool2, 256, 'conv3_1')\n",
    "\t\tconv3_2 = conv_layer(conv3_1, 256, 'conv3_2')\n",
    "\t\tconv3_3 = conv_layer(conv3_2, 256, 'conv3_3')\n",
    "\t\tpool3 = max_pool(conv3_3, 'pool3')\n",
    "\n",
    "\t\tconv4_1 = conv_layer(pool3, 512, 'conv4_1')\n",
    "\t\tconv4_2 = conv_layer(conv4_1, 512, 'conv4_2')\n",
    "\t\tconv4_3 = conv_layer(conv4_2, 512, 'conv4_3')\n",
    "\t\tpool4 = max_pool(conv4_3, 'pool4')\n",
    "\n",
    "\t\tconv5_1 = conv_layer(pool4, 512, 'conv5_1')\n",
    "\t\tconv5_2 = conv_layer(conv5_1, 512, 'conv5_2')\n",
    "\t\tconv5_3 = conv_layer(conv5_2, 512, 'conv5_3')\n",
    "\t\tpool5 = max_pool(conv5_3, 'pool5')\n",
    "\n",
    "\t\tflattened = tf.reshape(pool5, [-1, 1 * 1 * 512])\n",
    "\t\tfc6 = fc_layer(flattened, 1 * 1 * 512, 4096, name = 'fc6')\n",
    "\t\tdropout6 = dropout(fc6, self.KEEP_PROB)\n",
    "\n",
    "\t\tfc7 = fc_layer(dropout6, 4096, 4096, name = 'fc7')\n",
    "\t\tdropout7 = dropout(fc7, self.KEEP_PROB)\n",
    "\n",
    "\t\tself.fc8 = fc_layer(dropout7, 4096, self.NUM_CLASSES, relu = False, name = 'fc8')\n",
    "\n",
    "\n",
    "\n",
    "def conv_layer(x, num_filters, name, filter_height = 3, filter_width = 3,\n",
    "\tstride = 1, padding = 'SAME'):\n",
    "\n",
    "\t\"\"\"Create a convolution layer.\"\"\"\n",
    "\t\n",
    "\t# Get number of input channels\n",
    "\tinput_channels = int(x.get_shape()[-1])\n",
    "\n",
    "\twith tf.variable_scope(name) as scope:\n",
    "\n",
    "\t\t# Create tf variables for the weights and biases of the conv layer\n",
    "\t\tW = tf.get_variable('weights', shape = [filter_height, filter_width, input_channels, num_filters],\n",
    "\t\t\tinitializer = tf.random_normal_initializer(mean = 0.0, stddev = 0.01))\n",
    "\n",
    "\t\tb = tf.get_variable('biases', shape = [num_filters], initializer = tf.constant_initializer(0.0))\n",
    "\n",
    "\t\t# Perform convolution.\n",
    "\t\tconv = tf.nn.conv2d(x, W, strides = [1, stride, stride, 1], padding = padding)\n",
    "\t\t# Add the biases.\n",
    "\t\tz = tf.nn.bias_add(conv, b)\n",
    "\t\t# Apply ReLu non linearity.\n",
    "\t\ta = tf.nn.relu(z)\n",
    "\n",
    "\t\treturn a\n",
    "\n",
    "def fc_layer(x, input_size, output_size, name, relu = True):\n",
    "\n",
    "\t\"\"\"Create a fully connected layer.\"\"\"\n",
    "\t\n",
    "\twith tf.variable_scope(name) as scope:\n",
    "\n",
    "\t\t# Create tf variables for the weights and biases.\n",
    "\t\tW = tf.get_variable('weights', shape = [input_size, output_size],\n",
    "\t\t\tinitializer = tf.random_normal_initializer(mean = 0.0, stddev = 0.01))\n",
    "\n",
    "\t\tb = tf.get_variable('biases', shape = [output_size], initializer = tf.constant_initializer(0.0))\n",
    "\n",
    "\t\t# Matrix multiply weights and inputs and add biases.\n",
    "\t\tz = tf.nn.bias_add(tf.matmul(x, W), b)\n",
    "\n",
    "\t\tif relu:\n",
    "\t\t\t# Apply ReLu non linearity.\n",
    "\t\t\ta = tf.nn.relu(z)\n",
    "\t\t\treturn a\n",
    "\n",
    "\t\telse:\n",
    "\t\t\treturn z\n",
    "\n",
    "def max_pool(x, name, filter_height = 2, filter_width = 2,\n",
    "\tstride = 2, padding = 'VALID'):\n",
    "\n",
    "\t\"\"\"Create a max pooling layer.\"\"\"\n",
    "\n",
    "\treturn tf.nn.max_pool(x, ksize = [1, filter_height, filter_width, 1],\n",
    "\t\tstrides = [1, stride, stride, 1], padding = padding, name = name)\n",
    "\n",
    "def dropout(x, keep_prob):\n",
    "\n",
    "\t\"\"\"Create a dropout layer.\"\"\"\n",
    "\n",
    "\treturn tf.nn.dropout(x, keep_prob = keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 196, 196, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 98, 98, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 96, 96, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 48, 48, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 46, 46, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 23, 23, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 21, 21, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 10, 10, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               6554112   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,815,298\n",
      "Trainable params: 6,815,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(198, 198, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positive = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positive / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positive = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision_result = true_positive / (predicted_positives + K.epsilon())\n",
    "    return precision_result\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    f1_score = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy',recall_m, precision_m, f1_score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 8s 212ms/step - loss: 0.9980 - accuracy: 0.5667 - recall_m: 0.5667 - precision_m: 0.5667 - f1_score: 0.5667 - val_loss: 0.7045 - val_accuracy: 0.3333 - val_recall_m: 0.3333 - val_precision_m: 0.3333 - val_f1_score: 0.3333\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.7188 - accuracy: 0.6167 - recall_m: 0.6167 - precision_m: 0.6167 - f1_score: 0.6167 - val_loss: 0.6051 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.7108 - accuracy: 0.7500 - recall_m: 0.7500 - precision_m: 0.7500 - f1_score: 0.7500 - val_loss: 0.7608 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.7161 - accuracy: 0.8167 - recall_m: 0.8167 - precision_m: 0.8167 - f1_score: 0.8167 - val_loss: 0.4073 - val_accuracy: 0.6667 - val_recall_m: 0.6667 - val_precision_m: 0.6667 - val_f1_score: 0.6667\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 7s 218ms/step - loss: 0.6008 - accuracy: 0.7500 - recall_m: 0.7500 - precision_m: 0.7500 - f1_score: 0.7500 - val_loss: 0.3469 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.4198 - accuracy: 0.8000 - recall_m: 0.8000 - precision_m: 0.8000 - f1_score: 0.8000 - val_loss: 0.0657 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 6s 216ms/step - loss: 0.4693 - accuracy: 0.8167 - recall_m: 0.8167 - precision_m: 0.8167 - f1_score: 0.8167 - val_loss: 0.3338 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 6s 216ms/step - loss: 0.7207 - accuracy: 0.8500 - recall_m: 0.8500 - precision_m: 0.8500 - f1_score: 0.8500 - val_loss: 0.3596 - val_accuracy: 0.6667 - val_recall_m: 0.6667 - val_precision_m: 0.6667 - val_f1_score: 0.6667\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.4935 - accuracy: 0.8000 - recall_m: 0.8000 - precision_m: 0.8000 - f1_score: 0.8000 - val_loss: 0.4761 - val_accuracy: 0.6667 - val_recall_m: 0.6667 - val_precision_m: 0.6667 - val_f1_score: 0.6667\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.4218 - accuracy: 0.8500 - recall_m: 0.8500 - precision_m: 0.8500 - f1_score: 0.8500 - val_loss: 0.9651 - val_accuracy: 0.5000 - val_recall_m: 0.5000 - val_precision_m: 0.5000 - val_f1_score: 0.5000\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.4007 - accuracy: 0.8333 - recall_m: 0.8333 - precision_m: 0.8333 - f1_score: 0.8333 - val_loss: 0.7362 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.3823 - accuracy: 0.8500 - recall_m: 0.8500 - precision_m: 0.8500 - f1_score: 0.8500 - val_loss: 0.6034 - val_accuracy: 0.6667 - val_recall_m: 0.6667 - val_precision_m: 0.6667 - val_f1_score: 0.6667\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.2003 - accuracy: 0.9333 - recall_m: 0.9333 - precision_m: 0.9333 - f1_score: 0.9333 - val_loss: 0.0059 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.1310 - accuracy: 0.9667 - recall_m: 0.9667 - precision_m: 0.9667 - f1_score: 0.9667 - val_loss: 1.5338 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.4489 - accuracy: 0.8833 - recall_m: 0.8833 - precision_m: 0.8833 - f1_score: 0.8833 - val_loss: 0.0064 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.4369 - accuracy: 0.8500 - recall_m: 0.8500 - precision_m: 0.8500 - f1_score: 0.8500 - val_loss: 0.4993 - val_accuracy: 0.6667 - val_recall_m: 0.6667 - val_precision_m: 0.6667 - val_f1_score: 0.6667\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.2922 - accuracy: 0.9000 - recall_m: 0.9000 - precision_m: 0.9000 - f1_score: 0.9000 - val_loss: 9.1354e-04 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 6s 216ms/step - loss: 0.4009 - accuracy: 0.8833 - recall_m: 0.8833 - precision_m: 0.8833 - f1_score: 0.8833 - val_loss: 0.6654 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.6483 - accuracy: 0.9000 - recall_m: 0.9000 - precision_m: 0.9000 - f1_score: 0.9000 - val_loss: 0.4130 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 0.3934 - accuracy: 0.8500 - recall_m: 0.8500 - precision_m: 0.8500 - f1_score: 0.8500 - val_loss: 0.0331 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.4313 - accuracy: 0.8833 - recall_m: 0.8833 - precision_m: 0.8833 - f1_score: 0.8833 - val_loss: 0.1530 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.2519 - accuracy: 0.9333 - recall_m: 0.9333 - precision_m: 0.9333 - f1_score: 0.9333 - val_loss: 0.9643 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 7s 230ms/step - loss: 0.4382 - accuracy: 0.8833 - recall_m: 0.8833 - precision_m: 0.8833 - f1_score: 0.8833 - val_loss: 0.2638 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.3570 - accuracy: 0.8500 - recall_m: 0.8500 - precision_m: 0.8500 - f1_score: 0.8500 - val_loss: 0.3680 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.4925 - accuracy: 0.7833 - recall_m: 0.7833 - precision_m: 0.7833 - f1_score: 0.7833 - val_loss: 0.3150 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.2547 - accuracy: 0.8833 - recall_m: 0.8833 - precision_m: 0.8833 - f1_score: 0.8833 - val_loss: 0.4372 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.3128 - accuracy: 0.8667 - recall_m: 0.8667 - precision_m: 0.8667 - f1_score: 0.8667 - val_loss: 1.4150 - val_accuracy: 0.6667 - val_recall_m: 0.6667 - val_precision_m: 0.6667 - val_f1_score: 0.6667\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 0.4480 - accuracy: 0.8833 - recall_m: 0.8833 - precision_m: 0.8833 - f1_score: 0.8833 - val_loss: 0.0999 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.2343 - accuracy: 0.9500 - recall_m: 0.9500 - precision_m: 0.9500 - f1_score: 0.9500 - val_loss: 0.0144 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 6s 215ms/step - loss: 0.2967 - accuracy: 0.9333 - recall_m: 0.9333 - precision_m: 0.9333 - f1_score: 0.9333 - val_loss: 1.3960 - val_accuracy: 0.1667 - val_recall_m: 0.1667 - val_precision_m: 0.1667 - val_f1_score: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.3140 - accuracy: 0.9000 - recall_m: 0.9000 - precision_m: 0.9000 - f1_score: 0.9000 - val_loss: 1.6768 - val_accuracy: 0.6667 - val_recall_m: 0.6667 - val_precision_m: 0.6667 - val_f1_score: 0.6667\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.4529 - accuracy: 0.8833 - recall_m: 0.8833 - precision_m: 0.8833 - f1_score: 0.8833 - val_loss: 0.0748 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.2750 - accuracy: 0.9333 - recall_m: 0.9333 - precision_m: 0.9333 - f1_score: 0.9333 - val_loss: 0.0057 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.7131 - accuracy: 0.9000 - recall_m: 0.9000 - precision_m: 0.9000 - f1_score: 0.9000 - val_loss: 0.0113 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.5525 - accuracy: 0.8167 - recall_m: 0.8167 - precision_m: 0.8167 - f1_score: 0.8167 - val_loss: 0.1337 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.2673 - accuracy: 0.9167 - recall_m: 0.9167 - precision_m: 0.9167 - f1_score: 0.9167 - val_loss: 0.0057 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.0935 - accuracy: 0.9667 - recall_m: 0.9667 - precision_m: 0.9667 - f1_score: 0.9667 - val_loss: 1.0753 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 7s 248ms/step - loss: 0.3739 - accuracy: 0.8500 - recall_m: 0.8500 - precision_m: 0.8500 - f1_score: 0.8500 - val_loss: 0.0688 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.1341 - accuracy: 0.9333 - recall_m: 0.9333 - precision_m: 0.9333 - f1_score: 0.9333 - val_loss: 1.9899 - val_accuracy: 0.1667 - val_recall_m: 0.1667 - val_precision_m: 0.1667 - val_f1_score: 0.1667\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 6s 213ms/step - loss: 0.3786 - accuracy: 0.8667 - recall_m: 0.8667 - precision_m: 0.8667 - f1_score: 0.8667 - val_loss: 0.0727 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.1920 - accuracy: 0.9667 - recall_m: 0.9667 - precision_m: 0.9667 - f1_score: 0.9667 - val_loss: 0.7765 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.1707 - accuracy: 0.9500 - recall_m: 0.9500 - precision_m: 0.9500 - f1_score: 0.9500 - val_loss: 0.0726 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.4060 - accuracy: 0.8500 - recall_m: 0.8500 - precision_m: 0.8500 - f1_score: 0.8500 - val_loss: 0.8574 - val_accuracy: 0.6667 - val_recall_m: 0.6667 - val_precision_m: 0.6667 - val_f1_score: 0.6667\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.1558 - accuracy: 0.9500 - recall_m: 0.9500 - precision_m: 0.9500 - f1_score: 0.9500 - val_loss: 1.0427 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.2875 - accuracy: 0.8667 - recall_m: 0.8667 - precision_m: 0.8667 - f1_score: 0.8667 - val_loss: 0.1036 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.2551 - accuracy: 0.9333 - recall_m: 0.9333 - precision_m: 0.9333 - f1_score: 0.9333 - val_loss: 0.6950 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 7s 218ms/step - loss: 0.1580 - accuracy: 0.9667 - recall_m: 0.9667 - precision_m: 0.9667 - f1_score: 0.9667 - val_loss: 0.3777 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 7s 220ms/step - loss: 0.3318 - accuracy: 0.9333 - recall_m: 0.9333 - precision_m: 0.9333 - f1_score: 0.9333 - val_loss: 0.1375 - val_accuracy: 1.0000 - val_recall_m: 1.0000 - val_precision_m: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.2801 - accuracy: 0.9500 - recall_m: 0.9500 - precision_m: 0.9500 - f1_score: 0.9500 - val_loss: 0.4422 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 7s 226ms/step - loss: 0.1626 - accuracy: 0.9167 - recall_m: 0.9167 - precision_m: 0.9167 - f1_score: 0.9167 - val_loss: 0.2182 - val_accuracy: 0.8333 - val_recall_m: 0.8333 - val_precision_m: 0.8333 - val_f1_score: 0.8333\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=50, steps_per_epoch=30, validation_data = validation_generator, verbose = 1, validation_steps=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
